{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from scipy.stats import distributions as pdf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import sklearn.datasets as dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def make_data(num_samples, scatter):\n",
    "    np.random.seed(123)\n",
    "    class_means =[(1,8),(1,1),(8,1),(30,8)]\n",
    "    c1_samples =np.random.multivariate_normal(mean=class_means[0], \n",
    "                                             cov=[[scatter[0] *1, 0], [0, scatter[0] *1]], \n",
    "                                            size=num_samples[0])\n",
    "    \n",
    "    c2_samples = np.random.multivariate_normal(mean=class_means[1], \n",
    "                                            cov=[[scatter[1] *1, 0], [0, scatter[1] *1]], \n",
    "                                            size=num_samples[1])\n",
    "    \n",
    "    c3_samples = np.random.multivariate_normal(mean=class_means[2], \n",
    "                                            cov=[[scatter[2] *1, 0], [0, scatter[2] *1]], \n",
    "                                            size=num_samples[2])\n",
    "    \n",
    "    c4_samples = np.random.multivariate_normal(mean=class_means[3], \n",
    "                                            cov=[[scatter[3] *1, 0], [0, scatter[3] *1]], \n",
    "                                            size=num_samples[3])\n",
    "    \n",
    "    # labels\n",
    "    c1_labels = np.vstack((np.ones(c1_samples.shape[0]), \n",
    "                           np.zeros(c1_samples.shape[0]), \n",
    "                           np.zeros(c1_samples.shape[0]),\n",
    "                           np.zeros(c1_samples.shape[0]))).T\n",
    "    c2_labels = np.vstack((np.zeros(c2_samples.shape[0]), \n",
    "                           np.ones(c2_samples.shape[0]), \n",
    "                           np.zeros(c2_samples.shape[0]),\n",
    "                           np.zeros(c2_samples.shape[0]))).T\n",
    "    c3_labels = np.vstack((np.zeros(c3_samples.shape[0]), \n",
    "                           np.zeros(c3_samples.shape[0]), \n",
    "                           np.ones(c3_samples.shape[0]),\n",
    "                           np.zeros(c3_samples.shape[0]))).T\n",
    "    c4_labels = np.vstack((np.zeros(c4_samples.shape[0]), \n",
    "                           np.zeros(c4_samples.shape[0]), \n",
    "                           np.zeros(c4_samples.shape[0]),\n",
    "                           np.ones(c4_samples.shape[0]))).T\n",
    "    \n",
    "    \n",
    "    # feature matrix, weight matrix, label matrix (one-hot)\n",
    "    x = np.vstack((c1_samples, c2_samples, c3_samples, c4_samples))\n",
    "    x = np.hstack((np.ones(x.shape[0])[:,None],x)) # bias term\n",
    "    labels = np.vstack((c1_labels, c2_labels, c3_labels, c4_labels))\n",
    "    return x, labels, (c1_samples, c2_samples, c3_samples, c4_samples)\n",
    "\n",
    "def plot_data(c1_samples,c2_samples,c3_samples, c4_samples):\n",
    "    ax = plt.subplot()\n",
    "#     c1_samples,c2_samples,c3_samples=np.log(c1_samples),np.log(c2_samples),np.log(c3_samples)\n",
    "\n",
    "    ax.scatter(c1_samples[:,0],c1_samples[:,1])\n",
    "    ax.scatter(c2_samples[:,0],c2_samples[:,1])\n",
    "    ax.scatter(c3_samples[:,0],c3_samples[:,1])\n",
    "    ax.scatter(c4_samples[:,0],c4_samples[:,1])\n",
    "    return ax\n",
    "\n",
    "\n",
    "def loss_fn(x,weights,labels):    \n",
    "    # scores\n",
    "    s = x@weights.T  # scores\n",
    "\n",
    "    eps = np.max(s)  # constant for numerical stability\n",
    "    probs = (np.exp(s-eps))/ (np.sum(np.exp(s-eps), axis=1))[:,None]\n",
    "    # Loss function (negative log-likelihood)\n",
    "    loss = np.sum(-labels*np.log(probs))\n",
    "    dloss_dw = (labels*(probs-labels)).T@x\n",
    "    return loss, dloss_dw, probs\n",
    "\n",
    "\n",
    "def probability(x,weights):\n",
    "    s = x@weights.T  # scores\n",
    "    eps = np.max(s)  # constant for numerical stability\n",
    "    probs = (np.exp(s-eps))/ (np.sum(np.exp(s-eps), axis=1))[:,None]\n",
    "    return probs\n",
    "\n",
    "\n",
    "def grid(x,w, mode='sep'):\n",
    "    \n",
    "    h = .02  # step size in the mesh\n",
    "    x_min, x_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "    y_min, y_max = x[:, 2].min() - 1, x[:, 2].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    x_tmp=np.c_[xx.ravel(), yy.ravel()]\n",
    "    x_tmp = np.hstack((np.ones(x_tmp.shape[0])[:,None],x_tmp)) # bias term\n",
    "\n",
    "    pr = probability(x_tmp,w)\n",
    "\n",
    "    z = np.argmax(pr, axis=1)\n",
    "    \n",
    "    z = z.reshape(xx.shape)\n",
    "\n",
    "#     for i, ig in enumerate(grid_x):\n",
    "#         for j, jg in enumerate(grid_y):\n",
    "#             feats = np.array((1,ig,jg))[:,None].T\n",
    "#             pr=probability(feats,w)\n",
    "#             if mode == 'sep':\n",
    "#                 grid[i,j]=np.argmax(pr)\n",
    "#             elif mode == 'probs':\n",
    "#                 grid[i,j]=np.max(pr)\n",
    "\n",
    "    return xx, yy, z\n",
    "  \n",
    "\n",
    "def plot_decision_boundary(ax1, u, v, z, levels=None, colors=['k','k','k']):\n",
    "    # Basic contour plot\n",
    "#     fig1, ax1 = plt.subplots()\n",
    "    if levels == None:\n",
    "        ctp = ax1.contour(u, v, z, alpha=0.6)\n",
    "    else:\n",
    "        ctp = ax1.contour(u, v, z, levels=levels, colors=colors, alpha=0.6)\n",
    "        # Description of contours\n",
    "        fmt = {l: str(l) for l in ctp.levels}\n",
    "        ax1.clabel(ctp, ctp.levels, inline=True, fmt=fmt, fontsize=10)\n",
    "    return ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d70753cfdc4460d8dcb5d28d34fdb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5000, description='num_epochs', max=10000, step=500), Dropdown(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(num_epochs=(0,10000,500), \n",
    "          learning_rate=[0.01,0.02,0.03], \n",
    "          c1_samples='20',\n",
    "          c1_scatter=(1,8,0.4),\n",
    "          c2_samples='20',\n",
    "          c2_scatter=(1,8,0.4),\n",
    "          c3_samples='20',\n",
    "          c3_scatter=(1,20,0.4),\n",
    "          c4_samples='20',\n",
    "          c4_scatter=(1,8,0.4),)\n",
    "def multi_log_regression(num_epochs, \n",
    "                         learning_rate, \n",
    "                         c1_samples,\n",
    "                         c1_scatter,\n",
    "                         c2_samples, \n",
    "                         c2_scatter,\n",
    "                         c3_samples,\n",
    "                         c3_scatter,\n",
    "                         c4_samples,\n",
    "                         c4_scatter):\n",
    "    if  c1_samples.isdigit()==False or c2_samples.isdigit()==False or c3_samples.isdigit()==False or c4_samples.isdigit()==False:\n",
    "            pass\n",
    "    else:\n",
    "        c1_samples = int(c1_samples)\n",
    "        c2_samples = int(c2_samples)\n",
    "        c3_samples = int(c3_samples)\n",
    "        c4_samples = int(c4_samples)\n",
    "        x, labels, samples = make_data((c1_samples, c2_samples, c3_samples, c4_samples),\n",
    "                                       (c1_scatter, c2_scatter, c3_scatter, c4_scatter))\n",
    "\n",
    "        w = 0.001 * np.ones((4,x.shape[1])) # #classes x features\n",
    "        for epoch in range(num_epochs):\n",
    "                loss, dw, probs = loss_fn(x,w,labels)\n",
    "                acc = np.sum(np.argmax(labels)==np.argmax(probs))\n",
    "#                 print(w)\n",
    "                w -= learning_rate*dw\n",
    "        u,v,z = grid(x,w,mode='sep')\n",
    "        acc = np.sum(np.argmax(labels, axis=1)==np.argmax(probs, axis=1))\n",
    "        acc /= x.shape[0]\n",
    "        \n",
    "\n",
    "        ax = plot_data(*samples)\n",
    "        \n",
    "        # Plot missclassified data\n",
    "        if acc != 1.0:\n",
    "            idx = np.argmax(labels, axis=1)!=np.argmax(probs, axis=1)\n",
    "            ax.scatter(x[idx,1], x[idx,2], marker='x', c='k')\n",
    "        \n",
    "        try: \n",
    "            ax.text(9,10,'loss: {0:.4f}'.format(loss))\n",
    "            ax.text(9,11,'acc: {0:.4f}'.format(acc)) \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ax = plot_decision_boundary(ax, u,v,z)\n",
    "\n",
    "        \n",
    "        plt.xlim(-8,30)\n",
    "        plt.ylim(-8,15)\n",
    "\n",
    "\n",
    "        ax.figure\n",
    "        \n",
    "#     return ax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tmp = np.array([[  8.64093347,  -0.12633717,  -1.04936902],\n",
    " [  2.98071988 , -1.6248274  ,  1.19934607],\n",
    " [-11.61865335 ,  1.75416458 , -0.14697705]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array((1,3.73346091,14.25079417))[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.26863738e-02, 9.67312898e-01, 7.28159829e-07]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability(x.T, w_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array((1,2.38405744,5.61221124))[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "ts = np.array([[  8.64093347,  -0.12633717,  -1.04936902],\n",
    " [  2.98071988 , -1.6248274  ,  1.19934607],\n",
    " [-11.61865335 ,  1.75416458 , -0.14697705]])\n",
    "fd = np.array([[  0,  0,  1],\n",
    " [  0 , 1  ,  0],\n",
    " [1,  0 , 0]])\n",
    "print(ts[fd==1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
